"use strict";(self.webpackChunkplanning_to_learn=self.webpackChunkplanning_to_learn||[]).push([[245],{6056:function(e,t,a){a.r(t),a.d(t,{Head:function(){return O},default:function(){return z}});var l=a(6540),n=a(1612),r=a(4263),i=a(5178),s=a.p+"static/teaser-b2bf843257be7e81d6c3db733b75f9a5.mp4",o=a.p+"static/ball_ring_explainer-6ec34e8414474df63d2a33765acfe4ed.png",c=a.p+"static/main_results-2dfecf01c19915e85e873faccb50964a.png",m=a.p+"static/ball_ring_results_table-b05f37b643d08d89eb7135e11d0938fd.png",d=a.p+"static/main_ball_ring_full-31a90b17f9468df5cae7f7b38d52de04.mp4",u=a.p+"static/ball_ring_overview-d5669af88e417fa9101b62eaf8ca151d.mp4",p=a.p+"static/cleanup_playroom_results_table-355f76f00425b437a853cac7e18ffa64.png",h=a.p+"static/main_sweeping_full-d463d6b0841e79643de00ec456e5df54.mp4",f=a.p+"static/chair_misdetection-24cde10c93f834964bca7f2ea16c33ce.png",b=a.p+"static/hammer_misdetection-64021815974a15eee38e7e551e9b96a0.png",g=a.p+"static/tray_flip_fail-2a7f2c022653cb427dfc761e1b41192a.mp4",E=a.p+"static/sweep_fail-37c4cff288565d4c509cf3be5aeefd45.mp4",v=a.p+"static/object_finding_fail-cd05b8666cc3a9dc15dd74fa5c9f0cb8.mp4",x=a.p+"static/ring_on_table-467704863722f842aa22331e0cefa083.png",w=a.p+"static/ball_stuck-e290c04ede8d3344f8957c1d7d1ab19a.png",y=a.p+"static/brush_grasp_fail-f09d0a67681009f0184d2ea0dbc65847.gif",N=a.p+"static/tray_grasp_fail-98fb2cdc120edb6577cf8c769a510a26.gif";const k=e=>{let{children:t}=e;return l.createElement("h1",{className:"pb-1 mb-5 sm:mb-4 sm:leading-tight md:leading-tight lg:leading-tight font-bold text-center"},t)},_=e=>{let{website:t,children:a}=e;return l.createElement("div",{className:"flex flex-wrap justify-center text-2xl lg:text-2xl mb-6 sm:mb-5"},l.createElement("a",{className:"no-underline",href:t,target:"_blank"},a))},P=e=>{let{children:t}=e;return l.createElement("div",null,l.createElement("div",{className:"flex justify-center content-center"},l.createElement("p",{className:"font-semibold text-2xl sm:text-3xl m-1 sm:m-2"},"Abstract")),l.createElement("div",{className:"flex justify-center content-center"},l.createElement("p",{className:"text-justify font-light text-base sm:text-lg m-1 sm:m-1 max-w-[100%] sm:max-w-[640px]"},t)))},j=e=>{let{children:t,website:a,firstAuthor:n,affiliations:r,lastAuthor:i}=e;return l.createElement("span",{className:"text-center inline-block"},l.createElement("a",{href:a,target:"_blank",className:"font-normal no-underline text-[#009cff] hover:underline underline-offset-3 hover:transition-all"},t),n||r?l.createElement("sup",{className:"pl-0.5"},n?l.createElement("span",{className:"font-bold"},"*"):null,r||null):null,i?null:l.createElement(l.Fragment,null,", "))},S=e=>{let{children:t,website:a,number:n}=e;return l.createElement("span",{className:"text-center inline-block mr-4"},l.createElement("sup",{className:"mr-0.5"},n),l.createElement("a",{href:a,target:"_blank",className:"font-light no-underline text-[#009cff] hover:underline underline-offset-3 hover:transition-all"},t))},T=e=>{let{children:t,url:a,icon:n}=e;return l.createElement("span",{className:"text-center inline-block my-3.5 sm:my-2 mx-2"},l.createElement("a",{href:a,target:a.startsWith("#")?"_self":"_blank",className:"text-xl no-underline font-normal text-[#009cff] bg-[#f9f9f9] hover:bg-[#f4f4f4] hover:transition-all px-4 py-3 rounded-xl"},l.createElement("span",{className:"align-middle inline-flex justify-center mr-0.25"},n," "),l.createElement("span",null,t)))},R=e=>{let{children:t}=e;return l.createElement("div",{className:"mx-auto w-full max-w-[90%] format format-md md:format-base lg:max-w-5xl lg:format-lg format-blue dark:format-invert"},t)},C=e=>{let{children:t}=e;return l.createElement("main",{className:"pt-6 lg:pt-12 bg-white dark:bg-gray-900"},t)},I=e=>{let{children:t,id:a,demos:n,demos_label:r,video:i,hidden:s}=e;return l.createElement("div",{id:a,className:"realworld-result flex flex-row flex-wrap justify-items-center items-center mt-6"+(s?" hidden":"")},l.createElement("div",{className:"sm:basis-1/2 align-middle items-center sm:pr-5 md:pr-10 pb-4 sm:pb-0"},l.createElement("p",{className:"text-center font-medium text-2xl !mt-0 !mb-2"},t),l.createElement("img",{src:n,alt:t,className:"rounded-lg mx-auto !my-4 max-w-[80%] sm:max-w-[100%]"}),l.createElement("p",{className:"text-center !mt-2 !mb-0"},r)),l.createElement("div",{className:"sm:basis-1/2"},l.createElement("video",{autoPlay:!0,muted:!0,playsInline:!0,loop:!0,alt:t,className:"rounded-lg !my-0 !sm:my-0"},l.createElement("source",{src:i,type:"video/mp4"}))))},O=()=>l.createElement("title",null,"Practice Makes Perfect: Planning to Learn Skill Parameter Policies");var z=()=>l.createElement(l.Fragment,null,l.createElement(C,null,l.createElement(R,null,l.createElement(k,null,l.createElement("span",{className:"font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-blue-500 to-green-400"},"Practice Makes Perfect:")," ",l.createElement("br",null),l.createElement("span",{className:"font-normal text-stone-800"},"Planning to Learn Skill Parameter Policies")),l.createElement(_,{website:"https://arxiv.org/abs/2402.15025"},l.createElement("span",{className:"font-normal text-stone-600 hover:text-transparent hover:bg-clip-text hover:bg-gradient-to-r hover:from-blue-500 hover:to-green-400 hover:transition-all"},"RSS 2024")),l.createElement("div",{className:"flex flex-wrap justify-center text-xl lg:text-xl mb-4"},l.createElement(j,{website:"http://nishanthjkumar.com/",firstAuthor:!0,affiliations:"1,2"},"Nishanth Kumar"),l.createElement(j,{website:"https://web.mit.edu/tslvr/www/",firstAuthor:!0,affiliations:"1,2"},"Tom Silver"),l.createElement(j,{website:"https://wmcclinton.github.io/",affiliations:"1,2"},"Willie McClinton"),l.createElement(j,{website:"https://lfzhao.com/",affiliations:"1,3"},"Linfeng Zhao"),l.createElement(j,{website:"https://www.linkedin.com/in/stephen-proulx/?trk=public_profile_samename-profile",affiliations:"1"},"Stephen Proulx"),l.createElement(j,{website:"https://people.csail.mit.edu/tlp/",affiliations:"2"},"Tomás Lozano-Pérez"),l.createElement(j,{website:"https://people.csail.mit.edu/lpk/",affiliations:"2"},"Leslie Kaelbling"),l.createElement(j,{website:"https://www.linkedin.com/in/jennifer-barry-742a0799/",affiliations:"1",lastAuthor:!0},"Jennifer Barry")),l.createElement("div",{className:"flex flex-wrap justify-center text-xl lg:text-xl mb-1"},l.createElement(S,{website:"https://theaiinstitute.com/",number:"1"},"The AI Institute"),l.createElement(S,{website:"https://www.csail.mit.edu/",number:"2"},"MIT CSAIL"),l.createElement(S,{website:"https://www.northeastern.edu/",number:"3"},"Northeastern University")),l.createElement("div",{className:"flex flex-wrap justify-center text-l lg:text-l"},l.createElement("span",{className:"text-stone-600 text-center"},l.createElement("sup",{className:"mr-0.5"},"*"),"Indicates equal contribution.")),l.createElement("p",{className:"flex flex-wrap justify-center"},l.createElement(T,{url:"https://arxiv.org/pdf/2402.15025.pdf",icon:l.createElement(n.kl1,null)},"Paper"),l.createElement(T,{url:"https://www.youtube.com/watch?v=123DXatw1V8",icon:l.createElement(n.HiP,null)},"Video"),l.createElement(T,{url:"https://github.com/bdaiinstitute/predicators/releases/tag/planning-to-practice-ees",icon:l.createElement(r.NSh,null)},"Code")),l.createElement("video",{autoPlay:!0,controls:!0,muted:!0,playsInline:!0,loop:!0,alt:"Teaser Video",className:"border-2 border-slate-100 rounded-xl mx-auto max-w-[100%] sm:max-w-[95%]"},l.createElement("source",{src:s,type:"video/mp4"})),l.createElement("div",{className:"flex justify-center"},l.createElement("p",{className:"text-center text-xl !mt-0 !mb-2 font-medium max-w-[100%] md:max-w-[75%]"},"We enable a robot to rapidly and autonomously ",l.createElement("em",null,"specialize")," parameterized skills by ",l.createElement("em",null,"planning to practice")," them. The robot decides ",l.createElement("em",null,"what")," skills to practice and ",l.createElement("em",null,"how")," to practice them. The robot is left alone for hours, repeatedly practicing and improving."))),l.createElement(R,null,l.createElement("br",null),l.createElement("br",null),l.createElement(P,null,"One promising approach towards effective robot decision making in complex, long-horizon tasks is to sequence together ",l.createElement("em",null,"parameterized skills"),". We consider a setting where a robot is initially equipped with (1) a library of parameterized skills, (2) an AI planner for sequencing together the skills given a goal, and (3) a very general prior distribution for selecting skill parameters. Once deployed, the robot should rapidly and autonomously learn to improve its performance by specializing its skill parameter selection policy to the particular objects, goals, and constraints in its environment. In this work, we focus on the active learning problem of choosing which skills to ",l.createElement("em",null,"practice")," to maximize expected future task success. We propose that the robot should ",l.createElement("em",null,"estimate")," the competence of each skill, ",l.createElement("em",null,"extrapolate"),' the competence (asking: "how much would the competence improve through practice?"), and ',l.createElement("em",null,"situate")," the skill in the task distribution through competence-aware planning. This approach is implemented within a fully autonomous system where the robot repeatedly plans, practices, and learns without any environment resets. Through experiments in simulation, we find that our approach learns effective parameter policies more sample-efficiently than several baselines. Experiments in the real-world demonstrate our approach's ability to handle noise from perception and control and improve the robot's ability to solve two long-horizon mobile-manipulation tasks after a few hours of autonomous practice."),l.createElement("h2",{className:"font-semibold border-b-[1px] !mb-4"},"Approach Walkthrough"),l.createElement("img",{src:o,className:"rounded-lg mx-auto !my-4 max-w-[80%] sm:max-w-[100%]"}),l.createElement("p",null,"We propose ",l.createElement("b",null,"Estimate, Extrapolate, and Situate (EES)"),", an approach for planning to practice parameterized skills. During free time, the robot repeatedly chooses skills to practice. (Left) To select a skill, the robot first ",l.createElement("b",null,"estimates")," each skill's ",l.createElement("em",null,"competence"),", the probability that the skill will achieve its intended effects. The robot then ",l.createElement("b",null,"extrapolates"),' the competence, asking: "how much better would the skill get through practice?" Finally, the robot ',l.createElement("b",null,"situates"),' the competence, asking: "how much better overall at ',l.createElement("em",null,"human-given tasks"),' would I get by practicing this skill?" (Middle) Once a skill is selected, the robot ',l.createElement("em",null,"plans")," to satisfy the skill's initiation condition and then ",l.createElement("em",null,"practices")," the skill once. (Right) The practice data is used to improve the skill. Specifically, the robot learns ",l.createElement("em",null,"parameter policies")," that choose good continuous parameters for the skill."),l.createElement("p",null,"The video below illustrates EES in the ",l.createElement("em",null,"Ball-Ring environment"),". Here, the robot is tasked with placing a ball stably on a table. Through interaction and repeated practice, EES enables the robot to learn that (1) the ball cannot be directly placed on the table because it is slanted and will always cause the ball to roll off, (2) the yellow ring can only be placed on the left side of the table, where there is a high-friction material that prevents it from sliding off, (3) the best way to accomplish the goal is to place the ring on the left side and then place the ball into the ring. EES is implemented on a real robot system that uses perception and planning to achieve robust performance, even in the presense of ",l.createElement("b",null,"adversarial interventions"),"."),l.createElement("video",{autoPlay:!0,controls:!0,muted:!0,playsInline:!0,loop:!0,alt:"Approach overview in Ball Ring environment",className:"rounded-lg"},l.createElement("source",{src:u,type:"video/mp4"})),l.createElement("h2",{className:"font-semibold border-b-[1px] !mb-4"},"Results"),l.createElement("h3",{id:"results-graphs",className:"!mt-4"},"Simulated Environments"),l.createElement("p",null,"We compare EES to 7 baselines and find that it is consistently more sample-efficient across 3 simulated environments."),l.createElement("img",{src:c,className:"rounded-lg mx-auto !my-4 max-w-[80%] sm:max-w-[100%]"}),l.createElement("h3",{className:"!mt-4",id:"few-shot"},"Real Robot Environments"),l.createElement("p",null,"We implemented our approach on real-world versions of the simulated Ball-Ring and Cleanup Playroom environments. We measured the success rate under timeout across 5 random seeds. Results and accompanying demonstrative video of learning and evaluation are shown below. For full, ",l.createElement("em",null,"uncut and unedited")," versions of the robot's practice in these environments, see the following links: ",l.createElement("a",{href:"https://www.youtube.com/watch?v=cokB5ZR5Ick"},"Ball-Ring Uncut"),", ",l.createElement("a",{href:"https://www.youtube.com/watch?v=1gr-mIxdIOo"},"Cleanup Playroom Uncut")),l.createElement("div",{className:"my-4 leading-8"},l.createElement("span",{className:"text-xl mr-1"},"Show results for "),l.createElement("select",{className:"rounded-xl",onChange:e=>{const t=e.target.value,a=document.getElementById(t);if(null===a)return void console.log("div "+t+" is null! ");const l=document.getElementsByClassName("realworld-result");for(let n=0;n<l.length;n++)l[n]===a||l[n].classList.contains("hidden")||(l[n].classList.add("hidden"),l[n].getElementsByTagName("video")[0].currentTime=0,console.log("Hiding div "+l[n].id+" and reset video"));a.classList.remove("hidden"),console.log("Showing div "+a.id)}},l.createElement("option",{value:"cleanup_playroom_env"},"Cleanup Playroom Env"),l.createElement("option",{value:"ball_ring_env"},"Ball-Ring Env"))),l.createElement(I,{id:"cleanup_playroom_env",demos:p,demos_label:"Results in the Cleanup Playroom Env",video:h},"Results over 5 Seeds"),l.createElement(I,{id:"ball_ring_env",demos:m,hidden:!0,demos_label:"Results in the Ball-Ring Env",video:d},"Results over 5 Seeds"),l.createElement("h2",{className:"font-semibold border-b-[1px] !mb-4"},"Limitations and Dirty Laundry"),l.createElement("p",null,"Our robot system implementation is far from perfect and has a number of limitations. We display and discuss some of them here in the hopes that this promotes transparency and inspires future work. For more specific technical details around system implementation and limitations, please see our paper and code linked above."),l.createElement("h3",{id:"dead-end-states",className:"!mt-4"},"Dead-End States"),l.createElement("p",null,"A key assumption of our practicing framework is that the robot is always able to achieve the goal from any state it might ever encounter. This was made largely true in our environments, however, it did sometimes get violated in rare and unexpected circumstances, examples of which are shown below."),l.createElement("div",{className:"flex justify-center overflow-x-auto"},l.createElement("img",{src:x,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"}),l.createElement("img",{src:w,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"})),l.createElement("p",null,"In the left image, the ring got stuck in a position from which the robot's pick skill is unable to succeed (it assumes the ring is flat on a surface, never upright). On the right, the ball got trapped below the table such that the robot was unable to see or grasp it. Below, we show an example of the robot accidentally getting into a dead-end state in the Cleanup Playroom environment."),l.createElement("div",{className:"flex justify-center"},l.createElement("video",{autoPlay:!0,controls:!0,muted:!0,playsInline:!0,loop:!0,alt:"example deadend video",className:"rounded-lg max-w-[50%]"},l.createElement("source",{src:g,type:"video/mp4"}))),l.createElement("h3",{id:"perception-errors",className:"!mt-4"},"Perception Errors"),l.createElement("p",null,"Our perception pipeline relies on a combination of ",l.createElement("a",{href:"https://github.com/facebookresearch/Detic"},"Detic")," and ",l.createElement("a",{href:"https://segment-anything.com/"},"SAM")," to perform object detection and segmentation from robot camera images. To get to a high level of reliability, this required significant tuning of language prompts describing objects that are input to Detic. Despite this, false positive detections still occur."),l.createElement("div",{className:"flex justify-center overflow-x-auto"},l.createElement("img",{src:f,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"}),l.createElement("img",{src:b,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"})),l.createElement("p",null,"These misdetections are usually not catastrophic, but can cause substantial replanning and sometimes contribute to the robot getting into dead-end states mentioned above."),l.createElement("h3",{id:"skill-errors",className:"!mt-4"},"Skill Execution Errors"),l.createElement("p",null,"We leverage a library of skills to accomplish tasks, and each of these skills is prone to failures that cannot be improved even by practice..."),l.createElement("div",{className:"flex justify-center overflow-x-auto"},l.createElement("img",{src:y,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"}),l.createElement("img",{src:N,className:"rounded-lg mx-auto !my-4 max-w-[50%] sm:max-w-[50%]"})),l.createElement("p",null,"Similar to perception errors, these skill failures are usually overcome by replanning, but they can sometimes lead to dead end states."),l.createElement("div",{className:"flex justify-center"},l.createElement("video",{autoPlay:!0,controls:!0,muted:!0,playsInline:!0,loop:!0,alt:"example sweep failure video",className:"rounded-lg max-w-[50%]"},l.createElement("source",{src:E,type:"video/mp4"}))),l.createElement("h3",{id:"object-finding",className:"!mt-4"},"Object Finding"),l.createElement("p",null,"Our implementation features a relatively simple skill that attempts to navigate to random locations to find an object once its been lost (e.g., by having been dropped after moving). This can sometimes take a very long time to terminate."),l.createElement("div",{className:"flex justify-center"},l.createElement("video",{autoPlay:!0,controls:!0,muted:!0,playsInline:!0,loop:!0,alt:"example object finding failure video",className:"rounded-lg max-w-[50%]"},l.createElement("source",{src:v,type:"video/mp4"}))),l.createElement("h2",{id:"citation",className:"border-b-[3px]"},"Citation"),l.createElement("div",{className:"relative overflow-auto"},l.createElement("pre",{className:"bg-slate-100"},l.createElement("code",{id:"citation-bib",className:"font-normal text-slate-600"},"@inproceedings{kumar2024practice,\ntitle={Practice Makes Perfect: Planning to Learn Skill Parameter Policies}, \nauthor={Nishanth Kumar and Tom Silver and Willie McClinton and Linfeng Zhao and Stephen Proulx and Tomás Lozano-Pérez and Leslie Pack Kaelbling and Jennifer Barry},\nyear={2024},\nbooktitle={Robotics: Science and Systems (RSS)}\n}")),l.createElement("div",{className:"absolute top-0 right-0"},l.createElement("button",{className:"float-right text-2xl text-indigo-500 bg-white hover:bg-slate-50 hover:text-indigo-600 hover:transition-all rounded-full p-2 m-3 invisible md:visible",onClick:()=>{let e=document.getElementById("citation-bib"),t=document.createRange(),a=window.getSelection();null!=e&&null!=t&&null!=a&&(t.selectNode(e),a.removeAllRanges(),a.addRange(t))}},l.createElement(i.Ry6,null))))),l.createElement("footer",{className:"flex flex-col justify-center bg-gray-50 mt-8 py-8"},l.createElement("div",{className:"flex justify-center align-middle text-lg"},l.createElement("a",{role:"button",className:"text-blue-500",onClick:()=>{window.scrollTo({top:0,behavior:"smooth"})}},l.createElement("span",{className:"align-text-top inline-flex justify-center mr-0.25"},l.createElement(n.uCC,null)," "),l.createElement("span",null,"Back to Top"))),l.createElement("div",{className:"mt-2.5 text-center"},"Website adapted from ",l.createElement("a",{href:"https://github.com/f3rm/f3rm.github.io",target:"_blank",className:"text-blue-500"},l.createElement("span",{className:"align-text-top inline-flex justify-center mr-0.25"},l.createElement(r.NSh,null)," "),l.createElement("span",null,"F3RM Website Template"),".")))))},4084:function(e,t,a){a.d(t,{k5:function(){return c}});var l=a(6540),n={color:void 0,size:void 0,className:void 0,style:void 0,attr:void 0},r=l.createContext&&l.createContext(n),i=function(){return i=Object.assign||function(e){for(var t,a=1,l=arguments.length;a<l;a++)for(var n in t=arguments[a])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},i.apply(this,arguments)},s=function(e,t){var a={};for(var l in e)Object.prototype.hasOwnProperty.call(e,l)&&t.indexOf(l)<0&&(a[l]=e[l]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var n=0;for(l=Object.getOwnPropertySymbols(e);n<l.length;n++)t.indexOf(l[n])<0&&Object.prototype.propertyIsEnumerable.call(e,l[n])&&(a[l[n]]=e[l[n]])}return a};function o(e){return e&&e.map((function(e,t){return l.createElement(e.tag,i({key:t},e.attr),o(e.child))}))}function c(e){return function(t){return l.createElement(m,i({attr:i({},e.attr)},t),o(e.child))}}function m(e){var t=function(t){var a,n=e.attr,r=e.size,o=e.title,c=s(e,["attr","size","title"]),m=r||t.size||"1em";return t.className&&(a=t.className),e.className&&(a=(a?a+" ":"")+e.className),l.createElement("svg",i({stroke:"currentColor",fill:"currentColor",strokeWidth:"0"},t.attr,n,c,{className:a,style:i(i({color:e.color||t.color},t.style),e.style),height:m,width:m,xmlns:"http://www.w3.org/2000/svg"}),o&&l.createElement("title",null,o),e.children)};return void 0!==r?l.createElement(r.Consumer,null,(function(e){return t(e)})):t(n)}}}]);
//# sourceMappingURL=component---src-pages-index-tsx-36c5dab36b86b41a9ff0.js.map